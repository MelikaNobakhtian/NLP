{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TjPTaRB4mpCd"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab FAQ\n",
        "\n",
        "For some basic overview and features offered in Colab notebooks, check out: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "You need to use the colab GPU for this assignmentby selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
      ]
    },
    {
      "metadata": {
        "id": "s9IS9B9-yUU5"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup PyTorch\n",
        "All files are stored at /content/NLP/HW4/ folder\n"
      ]
    },
    {
      "metadata": {
        "id": "Z-6MQhMOlHXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "4db5d675-a949-4f45-ca65-6f535a6484ea"
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Setup python environment and change the current working directory\n",
        "######################################################################\n",
        "!pip install torch torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "%mkdir -p /content/NLP/HW4/\n",
        "%cd /content/NLP/HW4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow==4.0.0\n",
            "  Downloading Pillow-4.0.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 20.0 MB/s \n",
            "\u001b[?25hCollecting olefile\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 59.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow, olefile\n",
            "  Building wheel for Pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow: filename=Pillow-4.0.0-cp37-cp37m-linux_x86_64.whl size=1007448 sha256=a2637f498c191142981fdd0d09ea1e3c8bf56478e25a1a9c2d91f9bfd3700024\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/1e/24/dbc5e4964ea99cad93230a9013d934fb5adc322c3102f69e45\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=bdeed632e4b1b2c93dbba875f278e21dbc4ab3642478f49ab9b1948cf9e7c93c\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n",
            "Successfully built Pillow olefile\n",
            "Installing collected packages: olefile, Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires pillow!=8.3.*,>=5.3.0, but you have pillow 4.0.0 which is incompatible.\n",
            "scikit-image 0.18.3 requires pillow!=7.1.0,!=7.1.1,>=4.3.0, but you have pillow 4.0.0 which is incompatible.\n",
            "fastai 2.6.3 requires pillow>6.0.0, but you have pillow 4.0.0 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 4.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-4.0.0 olefile-0.46\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP/HW4\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9DaTdRNuUra7"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper code"
      ]
    },
    {
      "metadata": {
        "id": "4BIpGwANoQOg"
      },
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ]
    },
    {
      "metadata": {
        "id": "D-UJHBYZkh7f"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "import pickle as pkl\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "\n",
        "def get_file(fname,\n",
        "             origin,\n",
        "             untar=False,\n",
        "             extract=False,\n",
        "             archive_format='auto',\n",
        "             cache_dir='data'):\n",
        "    datadir = os.path.join(cache_dir)\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "\n",
        "    if untar:\n",
        "        untar_fpath = os.path.join(datadir, fname)\n",
        "        fpath = untar_fpath + '.tar.gz'\n",
        "    else:\n",
        "        fpath = os.path.join(datadir, fname)\n",
        "    \n",
        "    print(fpath)\n",
        "    if not os.path.exists(fpath):\n",
        "        print('Downloading data from', origin)\n",
        "\n",
        "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
        "        try:\n",
        "            try:\n",
        "                urlretrieve(origin, fpath)\n",
        "            except URLError as e:\n",
        "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
        "            except HTTPError as e:\n",
        "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
        "        except (Exception, KeyboardInterrupt) as e:\n",
        "            if os.path.exists(fpath):\n",
        "                os.remove(fpath)\n",
        "            raise\n",
        "\n",
        "    if untar:\n",
        "        if not os.path.exists(untar_fpath):\n",
        "            print('Extracting file.')\n",
        "            with tarfile.open(fpath) as archive:\n",
        "                archive.extractall(datadir)\n",
        "        return untar_fpath\n",
        "\n",
        "    if extract:\n",
        "        _extract_archive(fpath, datadir, archive_format)\n",
        "\n",
        "    return fpath\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "        \n",
        "def to_var(tensor, cuda):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "    if cuda:\n",
        "        return Variable(tensor.cuda())\n",
        "    else:\n",
        "        return Variable(tensor)\n",
        "\n",
        "\n",
        "def create_dir_if_not_exists(directory):\n",
        "    \"\"\"Creates a directory if it doesn't already exist.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "def save_loss_plot(train_losses, val_losses, opts):\n",
        "    \"\"\"Saves a plot of the training and validation loss curves.\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(train_losses)), train_losses)\n",
        "    plt.plot(range(len(val_losses)), val_losses)\n",
        "    plt.title('BS={}, nhid={}'.format(opts.batch_size, opts.hidden_size), fontsize=20)\n",
        "    plt.xlabel('Epochs', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)\n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(opts.checkpoint_path, 'loss_plot.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def checkpoint(encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Saves the current encoder and decoder models, along with idx_dict, which\n",
        "    contains the char_to_index and index_to_char mappings, and the start_token\n",
        "    and end_token values.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(opts.checkpoint_path, 'encoder.pt'), 'wb') as f:\n",
        "        torch.save(encoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'decoder.pt'), 'wb') as f:\n",
        "        torch.save(decoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'idx_dict.pkl'), 'wb') as f:\n",
        "        pkl.dump(idx_dict, f)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbvpn4MaV0I1"
      },
      "cell_type": "markdown",
      "source": [
        "## Data loader"
      ]
    },
    {
      "metadata": {
        "id": "XVT4TNTOV3Eg"
      },
      "cell_type": "code",
      "source": [
        "def read_lines(filename):\n",
        "    \"\"\"Read a file and split it into lines.\n",
        "    \"\"\"\n",
        "    lines = open(filename).read().strip().lower().split('\\n')\n",
        "    return lines\n",
        "\n",
        "\n",
        "def read_pairs(filename):\n",
        "    \"\"\"Reads lines that consist of two words, separated by a space.\n",
        "\n",
        "    Returns:\n",
        "        source_words: A list of the first word in each line of the file.\n",
        "        target_words: A list of the second word in each line of the file.\n",
        "    \"\"\"\n",
        "    lines = read_lines(filename)\n",
        "    source_words, target_words = [], []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            source, target = line.split()\n",
        "            source_words.append(source)\n",
        "            target_words.append(target)\n",
        "    return source_words, target_words\n",
        "\n",
        "\n",
        "def all_alpha_or_dash(s):\n",
        "    \"\"\"Helper function to check whether a string is alphabetic, allowing dashes '-'.\n",
        "    \"\"\"\n",
        "    return all(c.isalpha() or c == '-' for c in s)\n",
        "\n",
        "\n",
        "def filter_lines(lines):\n",
        "    \"\"\"Filters lines to consist of only alphabetic characters or dashes \"-\".\n",
        "    \"\"\"\n",
        "    return [line for line in lines if all_alpha_or_dash(line)]\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads (English, Pig-Latin) word pairs, and creates mappings from characters to indexes.\n",
        "    \"\"\"\n",
        "\n",
        "    source_lines, target_lines = read_pairs('data/pig_latin_data.txt')\n",
        "\n",
        "    # Filter lines\n",
        "    source_lines = filter_lines(source_lines)\n",
        "    target_lines = filter_lines(target_lines)\n",
        "\n",
        "    all_characters = set(''.join(source_lines)) | set(''.join(target_lines))\n",
        "\n",
        "    # Create a dictionary mapping each character to a unique index\n",
        "    char_to_index = { char: index for (index, char) in enumerate(sorted(list(all_characters))) }\n",
        "\n",
        "    # Add start and end tokens to the dictionary\n",
        "    start_token = len(char_to_index)\n",
        "    end_token = len(char_to_index) + 1\n",
        "    char_to_index['SOS'] = start_token\n",
        "    char_to_index['EOS'] = end_token\n",
        "\n",
        "    # Create the inverse mapping, from indexes to characters (used to decode the model's predictions)\n",
        "    index_to_char = { index: char for (char, index) in char_to_index.items() }\n",
        "\n",
        "    # Store the final size of the vocabulary\n",
        "    vocab_size = len(char_to_index)\n",
        "\n",
        "    line_pairs = list(set(zip(source_lines, target_lines)))  # Python 3\n",
        "\n",
        "    idx_dict = { 'char_to_index': char_to_index,\n",
        "                 'index_to_char': index_to_char,\n",
        "                 'start_token': start_token,\n",
        "                 'end_token': end_token }\n",
        "\n",
        "    return line_pairs, vocab_size, idx_dict\n",
        "\n",
        "\n",
        "def create_dict(pairs):\n",
        "    \"\"\"Creates a mapping { (source_length, target_length): [list of (source, target) pairs]\n",
        "    This is used to make batches: each batch consists of two parallel tensors, one containing\n",
        "    all source indexes and the other containing all corresponding target indexes.\n",
        "    Within a batch, all the source words are the same length, and all the target words are\n",
        "    the same length.\n",
        "    \"\"\"\n",
        "    unique_pairs = list(set(pairs))  # Find all unique (source, target) pairs\n",
        "\n",
        "    d = defaultdict(list)\n",
        "    for (s,t) in unique_pairs:\n",
        "        d[(len(s), len(t))].append((s,t))\n",
        "\n",
        "    return d\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRWfRdmVVjUl"
      },
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation code"
      ]
    },
    {
      "metadata": {
        "id": "wa5-onJhoSeM"
      },
      "cell_type": "code",
      "source": [
        "def string_to_index_list(s, char_to_index, end_token):\n",
        "    \"\"\"Converts a sentence into a list of indexes (for each character).\n",
        "    \"\"\"\n",
        "    return [char_to_index[char] for char in s] + [end_token]  # Adds the end token to each index list\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
        "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
        "    word independently, and then stitching the words back together with spaces between them.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data()\n",
        "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
        "\n",
        "\n",
        "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a given string from English to Pig-Latin.\n",
        "    \"\"\"\n",
        "\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_last_hidden = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_last_hidden\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "      ## slow decoding, recompute everything at each time\n",
        "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
        "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "      ni = ni[-1] #latest output token\n",
        "\n",
        "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "      \n",
        "      if ni == end_token:\n",
        "          break\n",
        "      else:\n",
        "          gen_string = \"\".join(\n",
        "              [index_to_char[int(item)] \n",
        "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def visualize_attention(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Generates a heatmap to show where attention is focused in each decoder step.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data()\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_hidden = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    produced_end_token = False\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "      ## slow decoding, recompute everything at each time\n",
        "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
        "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "      ni = ni[-1] #latest output token\n",
        "      \n",
        "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "      \n",
        "      if ni == end_token:\n",
        "          break\n",
        "      else:\n",
        "          gen_string = \"\".join(\n",
        "              [index_to_char[int(item)] \n",
        "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "    \n",
        "    if isinstance(attention_weights, tuple):\n",
        "      ## transformer's attention mweights\n",
        "      attention_weights, self_attention_weights = attention_weights\n",
        "    \n",
        "    all_attention_weights = attention_weights.data.cpu().numpy()\n",
        "    \n",
        "    for i in range(len(all_attention_weights)):\n",
        "      attention_weights_matrix = all_attention_weights[i].squeeze()\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(111)\n",
        "      cax = ax.matshow(attention_weights_matrix, cmap='bone')\n",
        "      fig.colorbar(cax)\n",
        "\n",
        "      # Set up axes\n",
        "      ax.set_yticklabels([''] + list(input_string) + ['EOS'], rotation=90)\n",
        "      ax.set_xticklabels([''] + list(gen_string) + (['EOS'] if produced_end_token else []))\n",
        "\n",
        "      # Show label at every tick\n",
        "      ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "      ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "      # Add title\n",
        "      plt.xlabel('Attention weights to the source sentence in layer {}'.format(i+1))\n",
        "      plt.tight_layout()\n",
        "      plt.grid('off')\n",
        "      plt.show()\n",
        "      #plt.savefig(save)\n",
        "\n",
        "      #plt.close(fig)\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def compute_loss(data_dict, encoder, decoder, idx_dict, criterion, optimizer, opts):\n",
        "    \"\"\"Train/Evaluate the model on a dataset.\n",
        "\n",
        "    Arguments:\n",
        "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Train the weights if an optimizer is given. None if only evaluate the model. \n",
        "        opts: The command-line arguments.\n",
        "\n",
        "    Returns:\n",
        "        mean_loss: The average loss over all batches from data_dict.\n",
        "    \"\"\"\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    losses = []\n",
        "    for key in data_dict:\n",
        "        input_strings, target_strings = zip(*data_dict[key])\n",
        "        input_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in input_strings]\n",
        "        target_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in target_strings]\n",
        "\n",
        "        num_tensors = len(input_tensors)\n",
        "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
        "\n",
        "        for i in range(num_batches):\n",
        "\n",
        "            start = i * opts.batch_size\n",
        "            end = start + opts.batch_size\n",
        "\n",
        "            inputs = to_var(torch.stack(input_tensors[start:end]), opts.cuda)\n",
        "            targets = to_var(torch.stack(target_tensors[start:end]), opts.cuda)\n",
        "\n",
        "            # The batch size may be different in each epoch\n",
        "            BS = inputs.size(0)\n",
        "\n",
        "            encoder_annotations, encoder_hidden = encoder(inputs)\n",
        "\n",
        "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            start_vector = torch.ones(BS).long().unsqueeze(1) * start_token  # BS x 1 --> 16x1  CHECKED\n",
        "            decoder_input = to_var(start_vector, opts.cuda)  # BS x 1 --> 16x1  CHECKED\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
        "\n",
        "            decoder_inputs = torch.cat([decoder_input, targets[:, 0:-1]], dim=1)  # Gets decoder inputs by shifting the targets to the right \n",
        "            \n",
        "            decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, encoder_hidden)\n",
        "            decoder_outputs_flatten = decoder_outputs.view(-1, decoder_outputs.size(2))\n",
        "            targets_flatten = targets.view(-1)\n",
        "            loss = criterion(decoder_outputs_flatten, targets_flatten)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            ## training if an optimizer is provided\n",
        "            if optimizer:\n",
        "              # Zero gradients\n",
        "              optimizer.zero_grad()\n",
        "              # Compute gradients\n",
        "              loss.backward()\n",
        "              # Update the parameters of the encoder and decoder\n",
        "              optimizer.step()\n",
        "              \n",
        "    mean_loss = np.mean(losses)\n",
        "    return mean_loss\n",
        "\n",
        "  \n",
        "\n",
        "def training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts):\n",
        "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
        "        * Prints training and val loss each epoch.\n",
        "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
        "        * Saves an attention map for TEST_WORD_ATTN each epoch\n",
        "\n",
        "    Arguments:\n",
        "        train_dict: The training word pairs, organized by source and target lengths.\n",
        "        val_dict: The validation word pairs, organized by source and target lengths.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Implements a step rule to update the parameters of the encoder and decoder.\n",
        "        opts: The command-line arguments.\n",
        "    \"\"\"\n",
        "\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    loss_log = open(os.path.join(opts.checkpoint_path, 'loss_log.txt'), 'w')\n",
        "\n",
        "    best_val_loss = 1e6\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(opts.nepochs):\n",
        "\n",
        "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
        "        \n",
        "        train_loss = compute_loss(train_dict, encoder, decoder, idx_dict, criterion, optimizer, opts)\n",
        "        val_loss = compute_loss(val_dict, encoder, decoder, idx_dict, criterion, None, opts)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            checkpoint(encoder, decoder, idx_dict, opts)\n",
        "\n",
        "        gen_string = translate_sentence(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
        "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, train_loss, val_loss, gen_string))\n",
        "\n",
        "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
        "        loss_log.flush()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        save_loss_plot(train_losses, val_losses, opts)\n",
        "\n",
        "\n",
        "def print_data_stats(line_pairs, vocab_size, idx_dict):\n",
        "    \"\"\"Prints example word pairs, the number of data points, and the vocabulary.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Data Stats'.center(80))\n",
        "    print('-' * 80)\n",
        "    for pair in line_pairs[:5]:\n",
        "        print(pair)\n",
        "    print('Num unique word pairs: {}'.format(len(line_pairs)))\n",
        "    print('Vocabulary: {}'.format(idx_dict['char_to_index'].keys()))\n",
        "    print('Vocab size: {}'.format(vocab_size))\n",
        "    print('=' * 80)\n",
        "\n",
        "\n",
        "def train(opts):\n",
        "    line_pairs, vocab_size, idx_dict = load_data()\n",
        "    print_data_stats(line_pairs, vocab_size, idx_dict)\n",
        "\n",
        "    # Split the line pairs into an 80% train and 20% val split\n",
        "    num_lines = len(line_pairs)\n",
        "    num_train = int(0.8 * num_lines)\n",
        "    train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
        "\n",
        "    # Group the data by the lengths of the source and target words, to form batches\n",
        "    train_dict = create_dict(train_pairs)\n",
        "    val_dict = create_dict(val_pairs)\n",
        "\n",
        "    ##########################################################################\n",
        "    ### Setup: Create Encoder, Decoder, Learning Criterion, and Optimizers ###\n",
        "    ##########################################################################\n",
        "    encoder = GRUEncoder(vocab_size=vocab_size, \n",
        "                         hidden_size=opts.hidden_size, \n",
        "                         opts=opts)\n",
        "\n",
        "    if opts.decoder_type == 'rnn':\n",
        "        decoder = RNNDecoder(vocab_size=vocab_size, \n",
        "                             hidden_size=opts.hidden_size)\n",
        "    elif opts.decoder_type == 'rnn_attention':\n",
        "        decoder = RNNAttentionDecoder(vocab_size=vocab_size, \n",
        "                                      hidden_size=opts.hidden_size, \n",
        "                                      attention_type=opts.attention_type)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    #### setup checkpoint path\n",
        "    model_name = 'h{}-bs{}-{}'.format(opts.hidden_size, \n",
        "                                      opts.batch_size, \n",
        "                                      opts.decoder_type)\n",
        "    opts.checkpoint_path = model_name\n",
        "    create_dir_if_not_exists(opts.checkpoint_path)\n",
        "    ####\n",
        "\n",
        "    if opts.cuda:\n",
        "        encoder.cuda()\n",
        "        decoder.cuda()\n",
        "        print(\"Moved models to GPU!\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=opts.learning_rate)\n",
        "\n",
        "    try:\n",
        "        training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts)\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return encoder, decoder\n",
        "      \n",
        "    return encoder, decoder\n",
        "\n",
        "\n",
        "def print_opts(opts):\n",
        "    \"\"\"Prints the values of all command-line arguments.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Opts'.center(80))\n",
        "    print('-' * 80)\n",
        "    for key in opts.__dict__:\n",
        "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
        "    print('=' * 80)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXNsLNkOn38w"
      },
      "cell_type": "markdown",
      "source": [
        "# Your code for NMT models"
      ]
    },
    {
      "metadata": {
        "id": "_BAfi_8yWB3y"
      },
      "cell_type": "markdown",
      "source": [
        "## GRU cell"
      ]
    },
    {
      "metadata": {
        "id": "9ztmyA5Ro67o"
      },
      "cell_type": "code",
      "source": [
        "class MyGRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyGRUCell, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        ## Input linear layers\n",
        "        self.Wiz = nn.Linear(input_size, hidden_size)\n",
        "        self.Wir = nn.Linear(input_size, hidden_size)\n",
        "        self.Wih = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        ## Hidden linear layers\n",
        "        self.Whz = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Whr = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Whh = nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"Forward pass of the GRU computation for one time step.\n",
        "\n",
        "        Arguments\n",
        "            x: batch_size x input_size\n",
        "            h_prev: batch_size x hidden_size\n",
        "\n",
        "        Returns:\n",
        "            h_new: batch_size x hidden_size\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        r = torch.sigmoid(self.Wir(x) + self.Whr(h_prev))\n",
        "        z = torch.sigmoid(self.Wiz(x) + self.Whz(h_prev))\n",
        "        g = torch.tanh(self.Wih(x) + r*self.Whh(h_prev))\n",
        "        h = (1 - z)*g + z*h_prev\n",
        "        return h\n",
        "\n",
        "        "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JBVFLEZWNC1"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU encoder / decoder"
      ]
    },
    {
      "metadata": {
        "id": "xaDt7XDmWRzC"
      },
      "cell_type": "code",
      "source": [
        "class GRUEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, opts):\n",
        "        super(GRUEncoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.opts = opts\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.gru = nn.GRUCell(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward pass of the encoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
        "\n",
        "        Returns:\n",
        "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len = inputs.size()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
        "        annotations = []\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
        "            hidden = self.gru(x, hidden)\n",
        "            annotations.append(hidden)\n",
        "\n",
        "        annotations = torch.stack(annotations, dim=1)\n",
        "        return annotations, hidden\n",
        "\n",
        "    def init_hidden(self, bs):\n",
        "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
        "        of a batch of sequences.\n",
        "\n",
        "        Arguments:\n",
        "            bs: The batch size for the initial hidden state.\n",
        "\n",
        "        Returns:\n",
        "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "        return to_var(torch.zeros(bs, self.hidden_size), self.opts.cuda)\n",
        "\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(RNNDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = nn.GRUCell(input_size=hidden_size, hidden_size=hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, annotations, hidden_init):\n",
        "        \"\"\"Forward pass of the non-attentional decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch. (batch_size x seq_len)\n",
        "            annotations: This is not used here. It just maintains consistency with the\n",
        "                    interface used by the AttentionDecoder class.\n",
        "            hidden_init: The hidden states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            None\n",
        "        \"\"\"        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        h_prev = hidden_init\n",
        "        for i in range(seq_len):\n",
        "            x = embed[:,i,:]  # Get the current time step input tokens, across the whole batch\n",
        "            h_prev = self.rnn(x, h_prev)  # batch_size x hidden_size\n",
        "            hiddens.append(h_prev)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, None      \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWe0RO5FWajD"
      },
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ]
    },
    {
      "metadata": {
        "id": "9GUK5A7CWhV8"
      },
      "cell_type": "code",
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # A two layer fully-connected network\n",
        "        # hidden_size*2 --> hidden_size, ReLU, hidden_size --> 1\n",
        "        self.attention_network = nn.Sequential(\n",
        "                                    nn.Linear(hidden_size*2, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(hidden_size, 1)\n",
        "                                 )\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the additive attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state. (batch_size x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x 1 x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The attention_weights must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        batch_size = queries.size(0) \n",
        "        expanded_queries = queries.unsqueeze(1).expand_as(keys) \n",
        "        concat_inputs = torch.cat((expanded_queries, keys), 2) \n",
        "        unnormalized_attention = self.attention_network(concat_inputs) \n",
        "        attention_weights = self.softmax(unnormalized_attention) \n",
        "        context = torch.bmm(attention_weights.squeeze(2).unsqueeze(1), values)\n",
        "        return context, attention_weights\n",
        "         "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pemjZo2XWtRt"
      },
      "cell_type": "markdown",
      "source": [
        "### Attention decoder"
      ]
    },
    {
      "metadata": {
        "id": "PfjF0Z-PWwPv"
      },
      "cell_type": "code",
      "source": [
        "class RNNAttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, attention_type='additive'):\n",
        "        super(RNNAttentionDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "\n",
        "        self.rnn = MyGRUCell(input_size=hidden_size*2, hidden_size=hidden_size)\n",
        "        self.attention = AdditiveAttention(hidden_size=hidden_size)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        \n",
        "    def forward(self, inputs, annotations, hidden_init):\n",
        "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
        "            annotations: The encoder hidden states for each step of the input.\n",
        "                         sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden_init: The final hidden states from the encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        attentions = []\n",
        "        h_prev = hidden_init\n",
        "        for i in range(seq_len):\n",
        "            # ------------\n",
        "            # FILL THIS IN\n",
        "            # ------------\n",
        "            embed_current = embed[:, i, :]\n",
        "            context, attention_weights = self.attention(h_prev, annotations, annotations)\n",
        "            embed_and_context = torch.cat((context.squeeze(1), embed_current), 1)\n",
        "            h_prev = self.rnn(embed_and_context, h_prev)\n",
        "            \n",
        "\n",
        "            \n",
        "            hiddens.append(h_prev)\n",
        "            attentions.append(attention_weights)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        attentions = torch.cat(attentions, dim=2) # batch_size x seq_len x seq_len\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, attentions\n",
        "        "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuNFd6LNo0-o"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ]
    },
    {
      "metadata": {
        "id": "kiUwiOITHTW4"
      },
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ]
    },
    {
      "metadata": {
        "id": "xwcFjsEpHRbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b4b66e-6d43-456a-db16-d42eed8c1925"
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Download Translation datasets\n",
        "######################################################################\n",
        "data_fpath = get_file(fname='pig_latin_data.txt', \n",
        "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_data.txt', \n",
        "                         untar=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pig_latin_data.txt\n",
            "Downloading data from http://www.cs.toronto.edu/~jba/pig_latin_data.txt\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hmQmyJDSRFKR"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN decoder"
      ]
    },
    {
      "metadata": {
        "id": "0LKaRF1jwhH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dae5e4c-b1f5-45c9-9398-5f888de3eb87"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': '',  # options: additive / scaled_dot\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "rnn_encoder, rnn_decoder = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, rnn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 100                                    \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.005                                  \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 20                                     \n",
            "                           decoder_type: rnn                                    \n",
            "                         attention_type:                                        \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('privately', 'ivatelypray')\n",
            "('crossing', 'ossingcray')\n",
            "('sprung', 'ungspray')\n",
            "('couched', 'ouchedcay')\n",
            "('passing', 'assingpay')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.320 | Val loss: 2.009 | Gen: ay-ay ay ontay ingay ontay\n",
            "Epoch:   1 | Train loss: 1.879 | Val loss: 1.850 | Gen: ay ayday ontiontiontay ingay ontay\n",
            "Epoch:   2 | Train loss: 1.724 | Val loss: 1.775 | Gen: ay-ay-ay-ay-ay-ay-ay ayday oontiontiontionway ingay-ayday ontionway\n",
            "Epoch:   3 | Train loss: 1.628 | Val loss: 1.699 | Gen: eway ayday oontiontionway ingay ontionway\n",
            "Epoch:   4 | Train loss: 1.560 | Val loss: 1.672 | Gen: eway ayday oontiontionway ingay oonday\n",
            "Epoch:   5 | Train loss: 1.522 | Val loss: 1.632 | Gen: eway ayday oonshay-otionway ingay oonday\n",
            "Epoch:   6 | Train loss: 1.480 | Val loss: 1.615 | Gen: eway ayway oontiontionway ingway oonday\n",
            "Epoch:   7 | Train loss: 1.448 | Val loss: 1.603 | Gen: eway ay-ayday-ayday oontiontionway inway oontionway\n",
            "Epoch:   8 | Train loss: 1.415 | Val loss: 1.583 | Gen: eway-away-ayday ayway oonsay-otionsay-oway inway onday-away-ayday\n",
            "Epoch:   9 | Train loss: 1.378 | Val loss: 1.541 | Gen: eway-ayday ay-inway oontingsay-ingsay-in inway oughedway\n",
            "Epoch:  10 | Train loss: 1.347 | Val loss: 1.525 | Gen: eway-away-away-away- ay-inway oonssay-oroushay-oon inway oughedway\n",
            "Epoch:  11 | Train loss: 1.329 | Val loss: 1.549 | Gen: estay ayingway oonssay-ingshay-inss iway ortay-ayday\n",
            "Epoch:  12 | Train loss: 1.314 | Val loss: 1.559 | Gen: eway ay-inway onsay-ortionsay-oway iway-away-away-away- orday-oway-ayday\n",
            "Epoch:  13 | Train loss: 1.291 | Val loss: 1.485 | Gen: ineday ay-inway ontingsay-ondway-own ishedway ortay-oday-oday-oday\n",
            "Epoch:  14 | Train loss: 1.273 | Val loss: 1.507 | Gen: eway-ayday ayinway oonsay-ingsay-ingsay ishay-ayday oughay-ayday\n",
            "Epoch:  15 | Train loss: 1.267 | Val loss: 1.534 | Gen: eway ay-ingay onsay-ortingsay iway orway-awlay\n",
            "Epoch:  16 | Train loss: 1.246 | Val loss: 1.485 | Gen: oway ayway-ingway onssay-orsingsay-ofs ishay ortay-oday-oway-ayda\n",
            "Epoch:  17 | Train loss: 1.219 | Val loss: 1.520 | Gen: estay ay-ybay ontingsay-ingsay-ing ishay oway-ayday\n",
            "Epoch:  18 | Train loss: 1.208 | Val loss: 1.504 | Gen: eway-ingray ayinway ontiontionway iway ortway-ownay\n",
            "Epoch:  19 | Train loss: 1.210 | Val loss: 1.459 | Gen: eway-ayday ayinway onssiantway-away-ayd iway ounway-away-ayday\n",
            "Epoch:  20 | Train loss: 1.185 | Val loss: 1.485 | Gen: eway-awlay ayhay-idway onsistingsay ishay orysay-inway\n",
            "Epoch:  21 | Train loss: 1.185 | Val loss: 1.436 | Gen: estay ayinway onssay-ortiationsway ishay-ybay orday-oway-ayday\n",
            "Epoch:  22 | Train loss: 1.163 | Val loss: 1.407 | Gen: estay ayinway onssingsay-ingsay-aw iway-ayday oughtway-away-ayday\n",
            "Epoch:  23 | Train loss: 1.144 | Val loss: 1.452 | Gen: eway-away-ayday ayinway onsingsay iway-awlay orksay\n",
            "Epoch:  24 | Train loss: 1.137 | Val loss: 1.442 | Gen: eshay ayinway onsisiontionsway iway-ybay okway-ayday\n",
            "Epoch:  25 | Train loss: 1.121 | Val loss: 1.416 | Gen: eshay ayinway onsisingsay iway-yway orkingway\n",
            "Epoch:  26 | Train loss: 1.114 | Val loss: 1.496 | Gen: essway ayingway onsiationtionway iway orksay-inway-away-ye\n",
            "Epoch:  27 | Train loss: 1.122 | Val loss: 1.377 | Gen: eshay ayinway onsistingsay iway-ybay orinway-awlay\n",
            "Epoch:  28 | Train loss: 1.105 | Val loss: 1.386 | Gen: esay-indedway ayinway onsisingsay iway-yearay orkway-ybay\n",
            "Epoch:  29 | Train loss: 1.112 | Val loss: 1.415 | Gen: otay-ybay away-yearay onsisiontingway iway orkway-away-ayday\n",
            "Epoch:  30 | Train loss: 1.123 | Val loss: 1.374 | Gen: eshay ayinway onssingsay iway oudgay-oday\n",
            "Epoch:  31 | Train loss: 1.092 | Val loss: 1.318 | Gen: esay ayinway onsistingsay iway orkway-awlay\n",
            "Epoch:  32 | Train loss: 1.061 | Val loss: 1.332 | Gen: esay ayinway onsisiontay-esay-awl iway orkway-awlay\n",
            "Epoch:  33 | Train loss: 1.041 | Val loss: 1.281 | Gen: esay ayinway onsisionsay iway-yearay orkway-ybay\n",
            "Epoch:  34 | Train loss: 1.033 | Val loss: 1.350 | Gen: estay ayinway onsistingsay iway-yway orkway-away-aypay\n",
            "Epoch:  35 | Train loss: 1.041 | Val loss: 1.349 | Gen: eshay ailay-awlay onsay-inencectedway iway-ybay orkway-inway-awlay\n",
            "Epoch:  36 | Train loss: 1.049 | Val loss: 1.311 | Gen: estay ailyway onsistationsway iway-ybay orkway-inway-awlay\n",
            "Epoch:  37 | Train loss: 1.051 | Val loss: 1.338 | Gen: esay aillay onsisensay iway orkway-awlay\n",
            "Epoch:  38 | Train loss: 1.021 | Val loss: 1.242 | Gen: estay ailay-ybay onsisiontingway iway-ybay orkway-inway-awlay\n",
            "Epoch:  39 | Train loss: 0.999 | Val loss: 1.253 | Gen: estay ailyway onsisentingsay iway-ybay orkway-inway-awlay\n",
            "Epoch:  40 | Train loss: 0.986 | Val loss: 1.265 | Gen: esay ailyway onsistablityway ishay orkway-ybay\n",
            "Epoch:  41 | Train loss: 1.000 | Val loss: 1.254 | Gen: estay ailyway onsisentingsay iway-ybay orkgay-ayday\n",
            "Epoch:  42 | Train loss: 1.002 | Val loss: 1.235 | Gen: estay ainway onsistay-ay-essay ishay orkway-inway\n",
            "Epoch:  43 | Train loss: 0.977 | Val loss: 1.263 | Gen: estay aiwlay onsisionsay-inesay-a iway-ybay orkway-away-yeay-awa\n",
            "Epoch:  44 | Train loss: 0.975 | Val loss: 1.278 | Gen: eway aiwlay onsisensay ishay okay-awlay\n",
            "Epoch:  45 | Train loss: 1.007 | Val loss: 1.281 | Gen: eshay ailyway onsisensay isway orkway-away-ayday\n",
            "Epoch:  46 | Train loss: 0.989 | Val loss: 1.251 | Gen: estay ailyway onsaningscay ishay orkway-inway-awlay\n",
            "Epoch:  47 | Train loss: 0.960 | Val loss: 1.217 | Gen: estay aiwlay onsisionsay iway-idway orkway-inway\n",
            "Epoch:  48 | Train loss: 0.937 | Val loss: 1.191 | Gen: estay aiwlay onsisenssay isway orkway-inway-awlay\n",
            "Epoch:  49 | Train loss: 0.933 | Val loss: 1.232 | Gen: estay aiwlay onsisingsay ishay orkway-inway\n",
            "Epoch:  50 | Train loss: 0.945 | Val loss: 1.316 | Gen: esay ayingway onsaningscay ishay orkway\n",
            "Epoch:  51 | Train loss: 0.976 | Val loss: 1.247 | Gen: estay ainway onsisentingway ishay orkway-inway\n",
            "Epoch:  52 | Train loss: 0.937 | Val loss: 1.196 | Gen: estay aimyray onsisentingway ishay orkway-inway-awlay\n",
            "Epoch:  53 | Train loss: 0.910 | Val loss: 1.186 | Gen: eshay aimyray onsingstay ishay orkway-inway-awlay\n",
            "Epoch:  54 | Train loss: 0.905 | Val loss: 1.199 | Gen: eshay aimyray onsisentsay isway orkway\n",
            "Epoch:  55 | Train loss: 0.904 | Val loss: 1.199 | Gen: eshay aimyray onsingsray isway orkway\n",
            "Epoch:  56 | Train loss: 0.910 | Val loss: 1.215 | Gen: estay aimyray onsingspay ishay orkway\n",
            "Epoch:  57 | Train loss: 0.909 | Val loss: 1.232 | Gen: eshay aimyray onsaningspay isway orkway\n",
            "Epoch:  58 | Train loss: 0.906 | Val loss: 1.199 | Gen: eshay aimyray onssingspay iway-idway orkway-awlay\n",
            "Epoch:  59 | Train loss: 0.907 | Val loss: 1.270 | Gen: eshay aimray-inway-away-ye onfinglisedcay isway orkway-inwayday\n",
            "Epoch:  60 | Train loss: 0.907 | Val loss: 1.201 | Gen: eshay airway onsingspay isway orkway\n",
            "Epoch:  61 | Train loss: 0.882 | Val loss: 1.216 | Gen: eshay aimyray oncingstay ishway orkway\n",
            "Epoch:  62 | Train loss: 0.875 | Val loss: 1.172 | Gen: estay aimyray onsingspay isway orkway\n",
            "Epoch:  63 | Train loss: 0.870 | Val loss: 1.158 | Gen: eshay aimray onsingspay iway-idway orkway-awanday\n",
            "Epoch:  64 | Train loss: 0.884 | Val loss: 1.248 | Gen: eshay airway onfaningspay isway orkway-inway-awlay\n",
            "Epoch:  65 | Train loss: 0.911 | Val loss: 1.230 | Gen: ehay airway oncisenssay isway orkway\n",
            "Epoch:  66 | Train loss: 0.878 | Val loss: 1.197 | Gen: estay airway onsingspay isway orkway\n",
            "Epoch:  67 | Train loss: 0.859 | Val loss: 1.143 | Gen: eshay airway onsinglisedway isway orkway\n",
            "Epoch:  68 | Train loss: 0.850 | Val loss: 1.201 | Gen: eshay airway oncingstay isway orkway\n",
            "Epoch:  69 | Train loss: 0.867 | Val loss: 1.181 | Gen: eshay airway onsinglisedway isway orkway-inway-awlay\n",
            "Epoch:  70 | Train loss: 0.855 | Val loss: 1.193 | Gen: eshay airway oncingstay isway orkway\n",
            "Epoch:  71 | Train loss: 0.852 | Val loss: 1.246 | Gen: eshay airway oncisenssay isway orkway\n",
            "Epoch:  72 | Train loss: 0.845 | Val loss: 1.227 | Gen: eshay airway onncissioncay isway orkway\n",
            "Epoch:  73 | Train loss: 0.834 | Val loss: 1.155 | Gen: eshay airway onsingpray isway orkway\n",
            "Epoch:  74 | Train loss: 0.826 | Val loss: 1.184 | Gen: eshay airway onnsicationcay isway orkway\n",
            "Epoch:  75 | Train loss: 0.827 | Val loss: 1.202 | Gen: eshay airway onncistionway isway orkway\n",
            "Epoch:  76 | Train loss: 0.855 | Val loss: 1.173 | Gen: ehay airway onncistenway isway orkway\n",
            "Epoch:  77 | Train loss: 0.845 | Val loss: 1.190 | Gen: eshay airway oncisionentsay isway orkway-inway-awlay\n",
            "Epoch:  78 | Train loss: 0.835 | Val loss: 1.171 | Gen: eshay airway onfinientensway isway orkway\n",
            "Epoch:  79 | Train loss: 0.809 | Val loss: 1.110 | Gen: eshay airway oncisionsay isway orkway\n",
            "Epoch:  80 | Train loss: 0.798 | Val loss: 1.137 | Gen: eshay airway oncistionway isway orkway\n",
            "Epoch:  81 | Train loss: 0.796 | Val loss: 1.114 | Gen: eshay airway oncisionsay isway orkway\n",
            "Epoch:  82 | Train loss: 0.795 | Val loss: 1.131 | Gen: eshay airway onnsicationcay isway orkway\n",
            "Epoch:  83 | Train loss: 0.787 | Val loss: 1.108 | Gen: eshay airway oncisionsay isway orkway\n",
            "Epoch:  84 | Train loss: 0.829 | Val loss: 1.252 | Gen: etay-ondway-inway-aw airway onsinginglycay isway orkway\n",
            "Epoch:  85 | Train loss: 0.826 | Val loss: 1.155 | Gen: estay airway oncisionsay isway orkway\n",
            "Epoch:  86 | Train loss: 0.790 | Val loss: 1.136 | Gen: eshay airway onncistionway isway orkay-awlay\n",
            "Epoch:  87 | Train loss: 0.778 | Val loss: 1.131 | Gen: eshay airway onsingpray isway orkway\n",
            "Epoch:  88 | Train loss: 0.775 | Val loss: 1.115 | Gen: eshay airway onnsiliscay isway orkay-awlay\n",
            "Epoch:  89 | Train loss: 0.772 | Val loss: 1.088 | Gen: ethay airdway onncistionway isway orkay-awlay\n",
            "Epoch:  90 | Train loss: 0.778 | Val loss: 1.197 | Gen: eshay airway onningsray-incepay-i isway orkway\n",
            "Epoch:  91 | Train loss: 0.795 | Val loss: 1.158 | Gen: eshay airrway onncay-acitentay isway orkay-awlay\n",
            "Epoch:  92 | Train loss: 0.788 | Val loss: 1.143 | Gen: eshay airdway oncisionlay-inentedw isway orkingway\n",
            "Epoch:  93 | Train loss: 0.768 | Val loss: 1.105 | Gen: eshay airdway oncisensay-inway-awl isway orkay-awlay\n",
            "Epoch:  94 | Train loss: 0.759 | Val loss: 1.096 | Gen: eshay airdway onnsiliscay isway orkay-awlay\n",
            "Epoch:  95 | Train loss: 0.753 | Val loss: 1.086 | Gen: ethay airdway onncistionway isway orkway\n",
            "Epoch:  96 | Train loss: 0.750 | Val loss: 1.100 | Gen: eshay airdway onncisensay-awelay isway orkay-aidedway\n",
            "Epoch:  97 | Train loss: 0.748 | Val loss: 1.108 | Gen: ethay airdway ondingspray isway orkway\n",
            "Epoch:  98 | Train loss: 0.744 | Val loss: 1.074 | Gen: ethay airdway oncisionlay isway orkay-awlay\n",
            "Epoch:  99 | Train loss: 0.739 | Val loss: 1.125 | Gen: ethay airdway onncistionway isway orkway\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airdway onncistionway isway orkway\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "p2kPGj5DFv7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c4ce59-0044-4f99-b5c6-8953c029c16d"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, rnn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airdway onncistionway isway orkway\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7cP7nl5NRJbu"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN attention decoder"
      ]
    },
    {
      "metadata": {
        "id": "nKlyfbuPDXDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f31977-08f7-49f4-f43b-f37ff81a0b7c"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'decoder_type': 'rnn_attention', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': 'additive',  # options: additive / scaled_dot\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "rnn_attn_encoder, rnn_attn_decoder = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                                   cuda: 1                                      \n",
            "                                nepochs: 100                                    \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                          learning_rate: 0.005                                  \n",
            "                               lr_decay: 0.99                                   \n",
            "                             batch_size: 64                                     \n",
            "                            hidden_size: 20                                     \n",
            "                           decoder_type: rnn_attention                          \n",
            "                         attention_type: additive                               \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('privately', 'ivatelypray')\n",
            "('crossing', 'ossingcray')\n",
            "('sprung', 'ungspray')\n",
            "('couched', 'ouchedcay')\n",
            "('passing', 'assingpay')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: dict_keys(['-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'SOS', 'EOS'])\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.205 | Val loss: 1.897 | Gen: esssay-esssay-esssay ay intinontay-ingay-ing intintintintintintin ongay\n",
            "Epoch:   1 | Train loss: 1.756 | Val loss: 1.730 | Gen: erteray ay-ay-ay-ay-ay-ay-ay ontiontiontiontionti insay-insay-insay-in onday\n",
            "Epoch:   2 | Train loss: 1.553 | Val loss: 1.591 | Gen: ethertay-estertay-es away-ay-ay-ay-ay-ay- onay-iongay isteray-insay-insay- oray-ingway-ingay-in\n",
            "Epoch:   3 | Train loss: 1.392 | Val loss: 1.495 | Gen: etway away ongay istay-inway oray\n",
            "Epoch:   4 | Train loss: 1.266 | Val loss: 1.464 | Gen: etway away onngay issay orray\n",
            "Epoch:   5 | Train loss: 1.155 | Val loss: 1.371 | Gen: ertway away ongay isway erway\n",
            "Epoch:   6 | Train loss: 1.035 | Val loss: 1.283 | Gen: ethtay-ebtway away onncay-onngingingway issay-issay-issay-is orway-ingray-ingway\n",
            "Epoch:   7 | Train loss: 0.912 | Val loss: 1.091 | Gen: ethtay aay-ay ondininginay isway orway\n",
            "Epoch:   8 | Train loss: 0.777 | Val loss: 1.150 | Gen: ewtay ay-ray onday-ingingingingwa ay-esay erungway\n",
            "Epoch:   9 | Train loss: 0.688 | Val loss: 1.153 | Gen: eththay arway ondiongingway isway orfigway\n",
            "Epoch:  10 | Train loss: 0.615 | Val loss: 1.227 | Gen: erthay airway ongitingningway isway orkingway\n",
            "Epoch:  11 | Train loss: 0.556 | Val loss: 0.860 | Gen: ethay iarway onigliongcay isay orkigway\n",
            "Epoch:  12 | Train loss: 0.461 | Val loss: 0.848 | Gen: ethay airway onditinagingway isway orkingway\n",
            "Epoch:  13 | Train loss: 0.418 | Val loss: 0.882 | Gen: eathay airway oditingay isway orkingway\n",
            "Epoch:  14 | Train loss: 0.397 | Val loss: 0.845 | Gen: ethay aay-irway onditioningnay isway roghingway\n",
            "Epoch:  15 | Train loss: 0.342 | Val loss: 0.699 | Gen: ethay airway ondointioningnay isway rotway\n",
            "Epoch:  16 | Train loss: 0.290 | Val loss: 0.551 | Gen: etay airway onditingingcay isway orkingway\n",
            "Epoch:  17 | Train loss: 0.242 | Val loss: 0.579 | Gen: ethay airway onitiongay isway orkingway\n",
            "Epoch:  18 | Train loss: 0.213 | Val loss: 0.542 | Gen: ethay airway onditinangcay isway orkingway\n",
            "Epoch:  19 | Train loss: 0.203 | Val loss: 0.449 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  20 | Train loss: 0.236 | Val loss: 1.368 | Gen: ethay ayqiway ongitiogingcay isway orkigway\n",
            "Epoch:  21 | Train loss: 0.384 | Val loss: 0.685 | Gen: ethay airway onditinagponigway isway orkingway\n",
            "Epoch:  22 | Train loss: 0.209 | Val loss: 0.442 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  23 | Train loss: 0.163 | Val loss: 0.419 | Gen: ethay airway onditionicgway isway orkingway\n",
            "Epoch:  24 | Train loss: 0.131 | Val loss: 0.364 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  25 | Train loss: 0.112 | Val loss: 0.365 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  26 | Train loss: 0.106 | Val loss: 0.316 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  27 | Train loss: 0.096 | Val loss: 0.440 | Gen: ethay airway ondititioningcay isway orkingway\n",
            "Epoch:  28 | Train loss: 0.126 | Val loss: 0.548 | Gen: ethay airway onditinangway isway orkingway\n",
            "Epoch:  29 | Train loss: 0.142 | Val loss: 0.732 | Gen: ethay airway onitineningcay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.163 | Val loss: 0.539 | Gen: ethaythaythaythaytha airway onotioningcay isway orkingway\n",
            "Epoch:  31 | Train loss: 0.123 | Val loss: 0.385 | Gen: ethay airway onditioningway isway orkingway\n",
            "Epoch:  32 | Train loss: 0.096 | Val loss: 0.434 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  33 | Train loss: 0.087 | Val loss: 0.280 | Gen: ethay airway onditiongncay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.064 | Val loss: 0.264 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  35 | Train loss: 0.053 | Val loss: 0.250 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  36 | Train loss: 0.049 | Val loss: 0.266 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  37 | Train loss: 0.043 | Val loss: 0.322 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  38 | Train loss: 0.044 | Val loss: 0.335 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  39 | Train loss: 0.045 | Val loss: 0.246 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  40 | Train loss: 0.040 | Val loss: 0.343 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  41 | Train loss: 0.051 | Val loss: 0.404 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.096 | Val loss: 0.720 | Gen: ethay airway onditingnay isway orkingway\n",
            "Epoch:  43 | Train loss: 0.150 | Val loss: 0.675 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  44 | Train loss: 0.167 | Val loss: 0.763 | Gen: ethay ayvay onditioningcay issay orkingway\n",
            "Epoch:  45 | Train loss: 0.197 | Val loss: 0.471 | Gen: ethay airway onlitionicgcay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.093 | Val loss: 0.308 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  47 | Train loss: 0.068 | Val loss: 0.267 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  48 | Train loss: 0.057 | Val loss: 0.201 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  49 | Train loss: 0.043 | Val loss: 0.198 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  50 | Train loss: 0.032 | Val loss: 0.204 | Gen: etay airway onditioningcay isway orkingway\n",
            "Epoch:  51 | Train loss: 0.027 | Val loss: 0.181 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  52 | Train loss: 0.024 | Val loss: 0.186 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  53 | Train loss: 0.021 | Val loss: 0.170 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  54 | Train loss: 0.019 | Val loss: 0.166 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  55 | Train loss: 0.016 | Val loss: 0.166 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  56 | Train loss: 0.015 | Val loss: 0.184 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  57 | Train loss: 0.015 | Val loss: 0.154 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  58 | Train loss: 0.013 | Val loss: 0.151 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  59 | Train loss: 0.015 | Val loss: 0.170 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  60 | Train loss: 0.015 | Val loss: 0.161 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  61 | Train loss: 0.012 | Val loss: 0.160 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  62 | Train loss: 0.011 | Val loss: 0.154 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  63 | Train loss: 0.084 | Val loss: 1.617 | Gen: ethay airway ontitiogway-ongongay issay otgingway\n",
            "Epoch:  64 | Train loss: 0.276 | Val loss: 1.014 | Gen: etatatatatatatatatat airway onditioiningcay isaway orkingway\n",
            "Epoch:  65 | Train loss: 0.136 | Val loss: 0.301 | Gen: etthay airway onditioningcay isway orkingway\n",
            "Epoch:  66 | Train loss: 0.044 | Val loss: 0.194 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  67 | Train loss: 0.028 | Val loss: 0.165 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  68 | Train loss: 0.019 | Val loss: 0.164 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  69 | Train loss: 0.016 | Val loss: 0.162 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  70 | Train loss: 0.013 | Val loss: 0.157 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  71 | Train loss: 0.011 | Val loss: 0.156 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  72 | Train loss: 0.010 | Val loss: 0.155 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  73 | Train loss: 0.009 | Val loss: 0.157 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  74 | Train loss: 0.009 | Val loss: 0.158 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  75 | Train loss: 0.009 | Val loss: 0.149 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  76 | Train loss: 0.008 | Val loss: 0.152 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  77 | Train loss: 0.007 | Val loss: 0.149 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  78 | Train loss: 0.007 | Val loss: 0.149 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  79 | Train loss: 0.006 | Val loss: 0.144 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  80 | Train loss: 0.006 | Val loss: 0.153 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  81 | Train loss: 0.005 | Val loss: 0.151 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  82 | Train loss: 0.005 | Val loss: 0.154 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  83 | Train loss: 0.005 | Val loss: 0.150 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  84 | Train loss: 0.084 | Val loss: 0.838 | Gen: ethay airway ondititionxay isway orkigway\n",
            "Epoch:  85 | Train loss: 0.228 | Val loss: 0.680 | Gen: etay airway onditiongcay isway orkingway\n",
            "Epoch:  86 | Train loss: 0.120 | Val loss: 0.453 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  87 | Train loss: 0.060 | Val loss: 0.186 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  88 | Train loss: 0.021 | Val loss: 0.163 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  89 | Train loss: 0.015 | Val loss: 0.159 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  90 | Train loss: 0.012 | Val loss: 0.152 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  91 | Train loss: 0.010 | Val loss: 0.149 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  92 | Train loss: 0.009 | Val loss: 0.149 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  93 | Train loss: 0.008 | Val loss: 0.148 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  94 | Train loss: 0.007 | Val loss: 0.146 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  95 | Train loss: 0.007 | Val loss: 0.146 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  96 | Train loss: 0.006 | Val loss: 0.145 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  97 | Train loss: 0.006 | Val loss: 0.144 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  98 | Train loss: 0.005 | Val loss: 0.142 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  99 | Train loss: 0.005 | Val loss: 0.142 | Gen: ethay airway onditioningcay isway orkingway\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onditioningcay isway orkingway\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vE-hKCxhF3iR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d88897-be8a-4d70-9da6-841a0005bd79"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onditioningcay isway orkingway\n"
          ]
        }
      ]
    }
  ]
}
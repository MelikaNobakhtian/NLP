{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KfKV8eKAtAP"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rxEc_HuUUYA4"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "import pprint\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHHNzIteAtAW"
      },
      "source": [
        "# Datasets download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O4WyhH9WL2f",
        "outputId": "a8c64e30-d6aa-428c-8d1e-31178791573c",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT4SVmSaAtAY"
      },
      "source": [
        "# Tagged sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GYqC2mfUj_S",
        "outputId": "cac0f271-dd76-4f2e-88e8-fb7643de111e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "tagged_sentences = treebank.tagged_sents()\n",
        "print(tagged_sentences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define features"
      ],
      "metadata": {
        "id": "9QV7CRj1G_Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def features(sentence, index):                       \n",
        "    return {\n",
        "        'word': sentence[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'is_before_period': True if index != len(sentence) - 1 and sentence[index + 1] == '.' else False,\n",
        "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
        "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
        "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
        "        'prefix-1': sentence[index][0],\n",
        "        'prefix-2': sentence[index][:2],\n",
        "        'suffix-1': sentence[index][-1],\n",
        "        'suffix-2': sentence[index][-2:],\n",
        "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "        'last_word_in_sentence': sentence[-1],\n",
        "        'is_numeric': sentence[index].isdigit(),\n",
        "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
        "    }"
      ],
      "metadata": {
        "id": "1XvQv_nDHDvH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Untag sentences"
      ],
      "metadata": {
        "id": "THMNEu_hCKdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def untag(tagged_sentence):\n",
        "    return [w for w, t in tagged_sentence]"
      ],
      "metadata": {
        "id": "VeqO78KbCSds"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Divide data to train part and test part"
      ],
      "metadata": {
        "id": "Fb-dKo1TCaIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff = int(.80 * len(tagged_sentences))                     \n",
        "training_sentences = tagged_sentences[:cutoff]\n",
        "test_sentences = tagged_sentences[cutoff:]"
      ],
      "metadata": {
        "id": "1iLAx5x3CZbC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform data to dataset"
      ],
      "metadata": {
        "id": "cIHkOeBOCoWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_dataset(tagged_sentences):\n",
        "    X, y = [], []\n",
        " \n",
        "    for tagged in tagged_sentences:\n",
        "        for index in range(len(tagged)):\n",
        "            X.append(features(untag(tagged), index))\n",
        "            y.append(tagged[index][1])\n",
        " \n",
        "    return X, y\n",
        " \n",
        "X, y = transform_to_dataset(training_sentences)"
      ],
      "metadata": {
        "id": "yjTwSkmJH6V8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define pipeline for training"
      ],
      "metadata": {
        "id": "swEkm_q7C_iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Pipeline([\n",
        "    ('vectorizer', DictVectorizer(sparse=False)),\n",
        "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
        "])\n",
        " \n",
        "clf.fit(X[:10000], y[:10000]) \n",
        " \n",
        "print ('Training completed')\n",
        " \n",
        "X_test, y_test = transform_to_dataset(test_sentences)\n",
        " \n",
        "print (\"Accuracy:\", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F95hBQcSIJkO",
        "outputId": "dd827047-f038-448e-9fb8-6a30cf5a3124"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed\n",
            "Accuracy: 0.8947552273067518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_tag(sentence): \n",
        "  tags = clf.predict([features(sentence, index) for index in range(len(sentence))]) \n",
        "  return list(zip(sentence, tags)) \n",
        "  \n",
        "pos_tag(word_tokenize('This is a test sentence!'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1UPIRe7Moh4",
        "outputId": "f3b05ec8-c200-48ba-c2b9-e78dffb31848"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('test', 'NN'),\n",
              " ('sentence', 'NN'),\n",
              " ('!', 'CD')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PoS_Tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}